{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.signal import clean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GroupShuffleSplit, ShuffleSplit\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "PATH = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load genetic data\n",
    "df_cnv = pd.read_csv(PATH + '....csv')\n",
    "df_cnv.set_index('SampleID', inplace=True)\n",
    "# Genetic covariates\n",
    "df_cnv = df_cnv.loc[:, ['TYPE', 'sum_loeuf_inv', 'n_genes', 'gene_id']]\n",
    "\n",
    "# Load clean data\n",
    "df_brain = pd.read_csv(PATH + '....csv', index_col=0)\n",
    "df_phens = pd.read_csv(PATH + '....csv', index_col=0)\n",
    "df_cov = pd.read_csv(PATH + '....csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_str = df_brain.index\n",
    "idx_phens = df_phens.index\n",
    "idx_genetic = df_cnv.index\n",
    "idx_cov = df_cov.index\n",
    "\n",
    "idx_all = list(set(idx_str) & set(idx_phens) & set(idx_genetic) & set(idx_cov))\n",
    "\n",
    "df_cnv = df_cnv.loc[idx_all, :]\n",
    "df_brain = df_brain.loc[idx_all, :]\n",
    "df_phens = df_phens.loc[idx_all, :]\n",
    "df_cov = df_cov.loc[idx_all, :]\n",
    "\n",
    "df_brain[:] = clean(df_brain.values, confounds=df_cov.loc[:, ['interview_age', 'sex', 'volume', 'scanner']].values,\n",
    "                    detrend=False, standardize=False)\n",
    "\n",
    "df_phens[:] = clean(df_phens.values, confounds=df_cov.loc[:, ['interview_age', 'sex']].values,\n",
    "                    detrend=False, standardize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final CCO permutations test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_is(x, y, pls_dim, pca_dim, n_splits, i_iter):\n",
    "    pls = PLSCanonical(n_components=pls_dim, scale=False,\n",
    "                       max_iter=1000, tol=1e-5)\n",
    "    pca = PCA(n_components=pca_dim)\n",
    "    scaler = StandardScaler()\n",
    "    # Split data into training and test sets\n",
    "    kf = ShuffleSplit(n_splits=n_splits, test_size=0.1, random_state=i_iter)\n",
    "    cov_is = np.zeros((n_splits, pls_dim))\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "        x_train = x[train_index]\n",
    "        y_train = y[train_index]\n",
    "        # Scale data\n",
    "        x_train_ss = scaler.fit_transform(x_train)\n",
    "        y_train_ss = scaler.fit_transform(y_train)\n",
    "        # Fit PCA\n",
    "        x_train_ss_pca = pca.fit_transform(x_train_ss)\n",
    "        y_train_ss_pca = pca.fit_transform(y_train_ss)\n",
    "        # Fit model\n",
    "        pls.fit(x_train_ss_pca, y_train_ss_pca)\n",
    "        # Predict y\n",
    "        x_pred = np.dot(x_train_ss_pca, pls.x_rotations_)\n",
    "        y_pred = np.dot(y_train_ss_pca, pls.y_rotations_)\n",
    "        for j in range(pls_dim):\n",
    "            cov_is[i, j] = np.cov(x_pred[:, j], y_pred[:, j])[0, 1]\n",
    "    cov_is = np.mean(cov_is, axis=0)\n",
    "    return cov_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_oos(x, y, pls_dim, pca_dim, n_splits, i_iter, groups):\n",
    "    pls = PLSCanonical(n_components=pls_dim, scale=False,\n",
    "                       max_iter=1000, tol=1e-5)                 \n",
    "    pca = PCA(n_components=pca_dim)\n",
    "    scaler = StandardScaler()\n",
    "    # Split data into training and test sets\n",
    "    gkf = GroupShuffleSplit(n_splits=n_splits, random_state=i_iter, test_size=0.1)\n",
    "    cov_oos = np.zeros((n_splits, pls_dim))\n",
    "    for i, (train_index, test_index) in enumerate(gkf.split(x, y, groups=groups)):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Scale data\n",
    "        x_train_ss = scaler.fit_transform(x_train)\n",
    "        x_test_ss = scaler.transform(x_test)\n",
    "        y_train_ss = scaler.fit_transform(y_train)\n",
    "        y_test_ss = scaler.transform(y_test)\n",
    "        # Fit PCA\n",
    "        x_train_ss_pca = pca.fit_transform(x_train_ss)\n",
    "        x_test_ss_pca = pca.transform(x_test_ss)\n",
    "        y_train_ss_pca = pca.fit_transform(y_train_ss)\n",
    "        y_test_ss_pca = pca.transform(y_test_ss)\n",
    "        # Fit model\n",
    "        pls.fit(x_train_ss_pca, y_train_ss_pca)\n",
    "        # Rotations\n",
    "        x_rotations = pls.x_rotations_\n",
    "        y_rotations = pls.y_rotations_\n",
    "        # Orient rotations\n",
    "        # x_rotations, y_rotations = orient_pls(x_rotations, y_rotations,\n",
    "        #                                       x_rotations_orig, y_rotations_orig)\n",
    "        # Predict y\n",
    "        x_pred = np.dot(x_test_ss_pca, x_rotations)\n",
    "        y_pred = np.dot(y_test_ss_pca, y_rotations)\n",
    "        for j in range(pls_dim):\n",
    "            cov_oos[i, j] = np.cov(x_pred[:, j], y_pred[:, j])[0, 1]\n",
    "    cov_oos = np.mean(cov_oos, axis=0)\n",
    "    return cov_oos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_is_permute(x, y, pls_dim, pca_dim, n_splits, i_perm, groups):\n",
    "    pls = PLSCanonical(n_components=pls_dim, scale=False,\n",
    "                       max_iter=1000, tol=1e-5)                 \n",
    "    pca = PCA(n_components=pca_dim)\n",
    "    scaler = StandardScaler()\n",
    "    # Split data into training and test sets\n",
    "    gkf = GroupShuffleSplit(n_splits=n_splits, random_state=i_perm, test_size=0.1)\n",
    "    cov_is = np.zeros((n_splits, pls_dim))\n",
    "    # for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    for i, (train_index, test_index) in enumerate(gkf.split(x, y, groups=groups)):\n",
    "        x_train = x[train_index]\n",
    "        y_train = y[train_index]\n",
    "        # Scale data\n",
    "        x_train_ss = scaler.fit_transform(x_train)\n",
    "        y_train_ss = scaler.fit_transform(y_train)\n",
    "        # Fit PCA\n",
    "        x_train_ss_pca = pca.fit_transform(x_train_ss)\n",
    "        y_train_ss_pca = pca.fit_transform(y_train_ss)\n",
    "        # Fit model\n",
    "        idx_rand = shuffle(np.arange(0, np.shape(y_train_ss_pca)[0]), random_state=i_perm)\n",
    "        y_train_ss_pca_perm = y_train_ss_pca[idx_rand, :]\n",
    "        pls.fit(x_train_ss_pca, y_train_ss_pca_perm)\n",
    "        # Rotations\n",
    "        x_rotations = pls.x_rotations_\n",
    "        y_rotations = pls.y_rotations_\n",
    "        # Predict y\n",
    "        x_pred = np.dot(x_train_ss_pca, x_rotations)\n",
    "        y_pred = np.dot(y_train_ss_pca_perm, y_rotations)\n",
    "        for j in range(pls_dim):\n",
    "            cov_is[i, j] = np.cov(x_pred[:, j], y_pred[:, j])[0, 1]\n",
    "    cov_is = np.mean(cov_is, axis=0)\n",
    "    return cov_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_covariance(x, y, pls_dim, pca_dim, n_splits, i_perm):\n",
    "    cov_perm_is = []\n",
    "    # Permute y\n",
    "    idx_rand = shuffle(np.arange(0, np.shape(y)[0]), random_state=i_perm)\n",
    "    y_perm = y[idx_rand, :]\n",
    "    cov_perm_is.append(covariance_is(x, y_perm, pls_dim, pca_dim, n_splits, i_perm)) # permuted insample covariance\n",
    "    return cov_perm_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate relationship matrix\n",
    "relationship_matrix = pd.read_csv(PATH + '.../king.kin0', sep='\\t')\n",
    "\n",
    "df_group = pd.DataFrame(data=np.arange(0, len(idx_all)), columns=['Group'], index=idx_all)\n",
    "for i in range(np.shape(relationship_matrix)[0]):\n",
    "    id1 = relationship_matrix.iloc[i, 1]\n",
    "    id2 = relationship_matrix.iloc[i, 3]\n",
    "    # Check if both IDs are in the index\n",
    "    if id1 in idx_all and id2 in idx_all:\n",
    "        # Check if both IDs have the same group ID\n",
    "        if df_group.loc[id1, 'Group'] != df_group.loc[id2, 'Group']:\n",
    "            # Assign the same group ID to both IDs\n",
    "            group_id = df_group.loc[id1, 'Group']\n",
    "            df_group.loc[df_group['Group'] == group_id, 'Group'] = df_group.loc[id2, 'Group']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross validation of PLS components \n",
    "# Initialize\n",
    "n_iter = 100\n",
    "n_perm = 100\n",
    "n_splits = 10\n",
    "pls_dim = 5\n",
    "pca_dim = 50\n",
    "\n",
    "# Prepare data\n",
    "x_ctrl = df_brain.values.astype('float')[df_cnv['TYPE'] == 'CTRL']\n",
    "y_ctrl = df_phens.values.astype('float')[df_cnv['TYPE'] == 'CTRL']\n",
    "\n",
    "id_group = df_group.loc[df_cnv['TYPE'] == 'CTRL', 'Group'].values\n",
    "\n",
    "# zscore\n",
    "x_ctrl_ss = StandardScaler().fit_transform(x_ctrl)\n",
    "y_ctrl_ss = StandardScaler().fit_transform(y_ctrl)\n",
    "\n",
    "# Fit PCA\n",
    "pca = PCA(n_components=pca_dim)\n",
    "x_ctrl_ss_pca = pca.fit_transform(x_ctrl_ss)\n",
    "y_ctrl_ss_pca = pca.fit_transform(y_ctrl_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of sample covariance for CTRL\n",
    "delayed_calls = [delayed(covariance_oos)(x_ctrl, y_ctrl, pls_dim, pca_dim, n_splits, i_iter, id_group) for i_iter in range(n_iter)]\n",
    "res = Parallel(n_jobs=8, prefer=\"threads\")(delayed_calls)\n",
    "cov_oos = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permuted insample covariance for CTRL\n",
    "delayed_calls = [delayed(covariance_is_permute)(x_ctrl, y_ctrl, pls_dim, pca_dim, n_splits, i_perm, id_group) for i_perm in range(n_perm)]\n",
    "res = Parallel(n_jobs=8, prefer=\"threads\")(delayed_calls)\n",
    "cov_perm_is = np.squeeze(np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of covariance and permuted covariance\n",
    "for i in range(5):\n",
    "    p_val = np.sum(cov_perm_is[:, i] > np.mean(cov_oos[:, i]))/n_perm\n",
    "    print('p-value: ' + str(p_val))\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(6, 3))\n",
    "    g = sns.kdeplot(cov_oos[:, i], alpha=0.5, label='Original OOS', fill=True)\n",
    "    g_perm = sns.kdeplot(cov_perm_is[:, i], alpha=0.5, label='Permuted', fill=True)\n",
    "    plt.legend(loc='upper right')\n",
    "    g.set_title('Mode ' + str(i+1))\n",
    "    g.set_xlabel('PLS scores covariance')\n",
    "    g.set_ylabel('Density')\n",
    "    g.set_yticks([])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNV_ABCD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
